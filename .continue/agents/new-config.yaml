# # This is an example configuration file
# # To learn more, see the full config.yaml reference: https://docs.continue.dev/reference

# name: Example Config
# version: 1.0.0
# schema: v1

# # Define which models can be used
# # https://docs.continue.dev/customization/models
# models:
#   - name: my gpt-5
#     provider: openai
#     model: gpt-5
#     wH-Af3el4AMJz1tapHrbeAKqCb9yhAXJsYJO_aIpazo9Si9RR5gNkl8zU713gQ3nsA
#   - uses: ollama/qwen2.5-coder-7b
#   - uses: anthropic/claude-4-sonnet
#     with:
#       ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}

# # MCP Servers that Continue can access
# # https://docs.continue.dev/customization/mcp-tools
# mcpServers:
#   - uses: anthropic/memory-mcp

{
  "models": [
    {
      "title": "Llama 3.2 (Ollama)",
      "provider": "ollama",
      "model": "llama3.2",
      "apiBase": "http://localhost:11434"
    }
  ]
}
  - uses: continue/memory-mcp
    with:
      CONTINUE_API_KEY: ${{ secrets.CONTINUE_API_KEY }}
